# import required libraries

from datetime import datetime
import requests
from bs4 import BeautifulSoup
from math import ceil 
import pandas as pd
import sys
"""This file is used to collect restaurant information from Yemek Sepeti.
Usage:
"initial YemekSepeti class in this way:
sirinevler = YemekSepeti("istanbul bahçelievler şirinevler mah")
These methods and attributes can be used:
sirinevler.find_restaurant() : generates a list containing restaurant names searched regarding the location.
sirinevler.restaurants : A list of restaurants.
sirinevler.restaurant_link_list: restaurant urls in restaurants in the list above.
sirinevler.location: a string value converted a url to be searched.
sirinevler.original_location: original location string as well as you entered.
sirinevler.collect_comments(): gather comments in restaurants list.
sirinevler.comments: a dictionary including comments and restaurant names generated by collect_comments() method.
sirinevler.restaurant_info: a nested list keeping general information about restaurants generated by general_info() method.
sirinevler.save(sirinevler.restaurant_info) or sirinevler.save(sirinevler.comments): save a file called location + date.csv from the restaurant_info list or coments."""
class YemekSepeti:
    """İmportant: To use this class, user agent value is necessary to get a request.
    Otherwise, the HTML response code will be 403.
    User Agent value should be a dictionary.
    Example: 
    User_Agent = {'User-agent' : 'xxxxxxxxxxx'}
    It can be found from this website:
    https://www.whatismybrowser.com/detect/what-is-my-user-agent/
    """

    def __init__(self, location:str): # İnitialising 
        self.original_location = location
        self.location = self.__unlocalize(location)
        self.URL = "https://yemeksepeti.com/"
        self.restaurants = []
        self.restaurant_links = []
        self.comments = {}
        self.restaurant_info = []
    
    # To convert the location in order to search.
    # This function is hidden.
    def __unlocalize(self, address):
        Turkish_Letters = "çÇğĞıİöÖşŞüÜ"
        Translated_Letters = "cCgGiIoOsSuU"
        Translation_Tables = str.maketrans(Turkish_Letters, Translated_Letters)
        address = address.translate(Translation_Tables)
        address = address.lower().split()
        # Thanks to this line, location will be "istanbul/bahcelievler-sirinevler-mah"
        return address[0] + "/" + "-".join(list(address[1::]))
    
    # This function requests to Yemek Sepeti.
    # As Well as __unlocalize function, this is hidden.
    def __request(self, url):
        # User Agent value taken from whatismybrowser should be enterred.
        User_Agent = {"User-agent": "Your User Agent"}
        response = requests.get(url, headers= User_Agent)
        if response.status_code == 200:
            return response.content # if successfull, contents of the web page.
        else: #for unsuccessfull requests
            print(f"""Something goes wrong!
            Please check your User Agent or your internet connection and retry later.
            Response of web page is {response.status_code}""")
            sys.exit()
    
    def find_restaurant(self):
        page_source = BeautifulSoup(self.__request(self.URL + self.location), "html.parser")
        # Each page includes maximum 154 restaurants.
        restaurant_page_count = ceil(int(page_source.find("div", {'class' : 'ys-result-count'}).text[36:-27]) / 154)
        for i in range(1, restaurant_page_count+1):
            page_source = BeautifulSoup(self.__request(self.URL + self.location + "?page=" + str(i)), "html.parser")
            # For every page, take restaurant information.
            restaurants = page_source.find_all("a", {'class' : 'restaurantName'})
            # extend relevant lists.
            self.restaurants.extend([i.text for i in restaurants])
            self.restaurant_links.extend([i.get('href') for i in restaurants])
        print(f"{len(self.restaurants)} restaurants were found.")
        
    def collect_comments(self):
        COMMENT_HREF = "?section=comments"
        for i in range(len(self.restaurants)): #for all restaurants.
            comments = []
            print(f"{i+1}. restaurant: {self.restaurants[i]}") #To follow.
            soup = BeautifulSoup(self.__request(self.URL + self.restaurant_links[i] + COMMENT_HREF), "html.parser")
            comment_page_count = ceil(int(soup.find("a", {'href' : '?section=comments'}).text[10:-1]) / 20)
            for j in range(1, comment_page_count+1): #to look all page and to get all comments
                soup = BeautifulSoup(self.__request(self.URL + self.restaurant_links[i] + COMMENT_HREF + "?page=" + str(j)), "html.parser")
                comment_tag = soup.find_all("div", {'class' : 'comment row'})
                comments.extend([k.p.text for k in comment_tag if k.i])
            print(len(comments))
            self.comments[self.restaurants[i]]= comments

    def general_info(self):
        for i in range(len(self.restaurants)):
            print(i+1, len(self.restaurants))
            soup = BeautifulSoup(self.__request(self.URL + self.restaurant_links[i]), "html.parser")
            try: # to pass the empty point value.
                comment_count = int(soup.find("a", {'href' : '?section=comments'}).text[10:-1])
                points = soup.find("div", {'class' : 'detailArea resPoints'}).find_all("span", {'class' : 'point'})
                service = float(points[-2].text.replace(",", "."))
                flavour = float(points[-1].text.replace(",", "."))
                if len (points) == 3:
                    speed = float(points[0].text.replace(",", "."))
                    mean = round((speed + service + flavour) / 3, 1)
                elif len(points) == 2:
                    #some restaurants use Yemet Sepeti curriers so they have not speed point.
                    speed = None
                    mean = round((service + flavour) / 2, 1)
                self.restaurant_info.append((self.restaurants[i], self.location, comment_count, speed, service, flavour, mean))
            except ValueError:
                pass


    
    def save(self, data):
        now = datetime.now()
        date_formatted = datetime.strftime(now, '%d.%m.%Y %H.%M.%S')
        if isinstance(data, dict):
            data = [(i, j) for i in data.keys() for j in data[i]]
            df = pd.DataFrame(data, columns=["restaurant name", "comment"], index=None)
        elif isinstance(data, list):
            df = pd.DataFrame(data, columns=['name', 'location', 'comments count', 'speed', 'service', 'flavour', 'mean'])
        df.to_csv(f"{self.original_location} {date_formatted}.csv", index=False, encoding="utf-8")
                



# example initialising:
atakoy = YemekSepeti('istanbul bakırköy ataköy 5 kısım')
